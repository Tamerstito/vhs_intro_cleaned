{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSNHjxLjzm7+EnsrQU50rJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tamerstito/vhs_intro_cleaned/blob/main/MNIST_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5lJ_bNKsD_Sz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf93d9a4-511f-4729-8648-87283f2bd7ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "keras.datasets.mnist.load_data(path=\"mnist.npz\")  # our dataset\n",
        "\n",
        "# Raw 28×28 grayscale images\n",
        "(x_train_raw, y_train), (x_test_raw, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale to [0, 1] (Normalization)\n",
        "x_train_raw = x_train_raw.astype(\"float32\") / 255.0\n",
        "x_test_raw  = x_test_raw.astype(\"float32\")  / 255.0\n",
        "\n",
        "x_train_flat = x_train_raw.reshape(-1, 28 * 28)        # (60000, 784)\n",
        "x_test_flat  = x_test_raw.reshape(-1, 28 * 28)         # (10000, 784)\n",
        "\n",
        "x_train_cnn  = x_train_raw[..., np.newaxis]            # (60000, 28, 28, 1)\n",
        "x_test_cnn   = x_test_raw[..., np.newaxis]             # (10000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"flat input  :\", x_train_flat.shape)\n",
        "print(\"cnn  input  :\", x_train_cnn.shape)"
      ],
      "metadata": {
        "id": "q8bCg1tyEu2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d6376e-0433-4cbd-8e97-e641fa153ca3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flat input  : (60000, 784)\n",
            "cnn  input  : (60000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "idx = 9\n",
        "plt.imshow(x_train_raw[idx], cmap='gray')\n",
        "plt.title(f\"Label: {y_train[idx]}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9143HeNJGmwj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "828d8969-2e26-4444-bd89-f2aeaab75899"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "unique_classes, counts = np.unique(y_train, return_counts=True) # receiving inputs for the classes and amounf of respective pixels/images for each class (0-9)\n",
        "print(\"Classes:\", unique_classes)\n",
        "print(\"Counts:\", counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paXOuKYTGuaB",
        "outputId": "b0107c13-f4a0-43ae-9975-2a6712ffcb5c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: [0 1 2 3 4 5 6 7 8 9]\n",
            "Counts: [5923 6742 5958 6131 5842 5421 5918 6265 5851 5949]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model_NN = keras.Sequential([\n",
        "    layers.Dense(256, activation='relu', input_shape=(28 * 28,)),  # <‑‑ tuple here\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64,  activation='relu'),\n",
        "    layers.Dense(10,  activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "XuPiKlnwGw-k"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d8d_tFELU20s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a train model function\n",
        "\n",
        "def train_model(model, x_train, y_train, x_test,  y_test, optimizer='adam',\n",
        "                epochs=10, batch_size=32):\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        validation_data=(x_test, y_test),\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        verbose=1\n",
        "    )\n",
        "    return history"
      ],
      "metadata": {
        "id": "piSBFGqtGzCt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Each Model\n",
        "\n",
        "# Dense NN — Adam\n",
        "history_NN_adam = train_model(\n",
        "    model_NN,\n",
        "    x_train_flat, y_train,\n",
        "    x_test_flat,  y_test,\n",
        "    optimizer='adam'\n",
        ")\n",
        "model_NN.save_weights('mnist_nn.weights.h5')              # saving the weights\n",
        "\n",
        "# Dense NN — SGD\n",
        "model_NN_sgd   = keras.models.clone_model(model_NN)       # new copy\n",
        "history_NN_sgd = train_model(\n",
        "    model_NN_sgd,\n",
        "    x_train_flat, y_train,\n",
        "    x_test_flat,  y_test,\n",
        "    optimizer='sgd'\n",
        ")\n",
        "model_NN_sgd.save_weights('mnist_nn_sgd.weights.h5')      # saving the weights\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BitD-3Fm0iCK",
        "outputId": "ef648eb2-aeee-4530-c0ea-1fd9c3c479a6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9955 - loss: 0.0153 - val_accuracy: 0.9792 - val_loss: 0.1046\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9957 - loss: 0.0161 - val_accuracy: 0.9780 - val_loss: 0.1048\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9966 - loss: 0.0114 - val_accuracy: 0.9780 - val_loss: 0.1049\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9968 - loss: 0.0090 - val_accuracy: 0.9788 - val_loss: 0.1184\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0103 - val_accuracy: 0.9797 - val_loss: 0.1181\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0094 - val_accuracy: 0.9794 - val_loss: 0.1193\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9970 - loss: 0.0092 - val_accuracy: 0.9773 - val_loss: 0.1257\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0075 - val_accuracy: 0.9808 - val_loss: 0.1101\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0104 - val_accuracy: 0.9785 - val_loss: 0.1195\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 7ms/step - accuracy: 0.9975 - loss: 0.0087 - val_accuracy: 0.9814 - val_loss: 0.1031\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7053 - loss: 1.0575 - val_accuracy: 0.9139 - val_loss: 0.2948\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9208 - loss: 0.2713 - val_accuracy: 0.9298 - val_loss: 0.2292\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9392 - loss: 0.2082 - val_accuracy: 0.9477 - val_loss: 0.1783\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9519 - loss: 0.1662 - val_accuracy: 0.9537 - val_loss: 0.1543\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9590 - loss: 0.1435 - val_accuracy: 0.9611 - val_loss: 0.1268\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9655 - loss: 0.1198 - val_accuracy: 0.9626 - val_loss: 0.1224\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9712 - loss: 0.1017 - val_accuracy: 0.9663 - val_loss: 0.1106\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9752 - loss: 0.0885 - val_accuracy: 0.9697 - val_loss: 0.0995\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9772 - loss: 0.0783 - val_accuracy: 0.9714 - val_loss: 0.0926\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9793 - loss: 0.0715 - val_accuracy: 0.9724 - val_loss: 0.0922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the histories to DataFrames\n",
        "\n",
        "history_df_NN_adam = pd.DataFrame(history_NN_adam.history)\n",
        "history_df_NN_sgd = pd.DataFrame(history_NN_sgd.history)"
      ],
      "metadata": {
        "id": "IwN0HQxWHkti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model — Adam\n",
        "model_CNN = keras.Sequential([\n",
        "    keras.Input(shape=(28, 28, 1)),\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(units=10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "stVokrGFHluh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_CNN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "PiS-16awLGxe",
        "outputId": "e318242b-8df9-4b0a-bc1a-4e567966a75b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m16,010\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,010</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,480\u001b[0m (408.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,480</span> (408.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,826\u001b[0m (136.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,826</span> (136.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m69,654\u001b[0m (272.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,654</span> (272.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_CNN.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "0igO6_wuLK4s"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_CNN_adam = model_CNN.fit(\n",
        "    x_train_cnn, y_train,\n",
        "    validation_data=(x_test_cnn, y_test),\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model_CNN.save_weights('mnist_cnn.weights.h5')"
      ],
      "metadata": {
        "id": "ZMc-DfTvQB8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0c5f588-bac9-46c7-e988-eb3b186a10a5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 29ms/step - accuracy: 0.8693 - loss: 0.4310 - val_accuracy: 0.9806 - val_loss: 0.0628\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 30ms/step - accuracy: 0.9742 - loss: 0.0840 - val_accuracy: 0.9839 - val_loss: 0.0443\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 31ms/step - accuracy: 0.9794 - loss: 0.0650 - val_accuracy: 0.9877 - val_loss: 0.0368\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 31ms/step - accuracy: 0.9819 - loss: 0.0546 - val_accuracy: 0.9886 - val_loss: 0.0335\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 29ms/step - accuracy: 0.9854 - loss: 0.0451 - val_accuracy: 0.9902 - val_loss: 0.0291\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 30ms/step - accuracy: 0.9879 - loss: 0.0408 - val_accuracy: 0.9900 - val_loss: 0.0291\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 29ms/step - accuracy: 0.9875 - loss: 0.0392 - val_accuracy: 0.9906 - val_loss: 0.0266\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 31ms/step - accuracy: 0.9884 - loss: 0.0370 - val_accuracy: 0.9913 - val_loss: 0.0244\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 33ms/step - accuracy: 0.9898 - loss: 0.0334 - val_accuracy: 0.9919 - val_loss: 0.0246\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 29ms/step - accuracy: 0.9888 - loss: 0.0334 - val_accuracy: 0.9907 - val_loss: 0.0287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the saved weights — So I don't need to rerun all the models again.\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Dense NN — Adam\n",
        "dense_NN_adam_reload = keras.Sequential([\n",
        "    keras.Input(shape=(28 * 28,)),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64,  activation='relu'),\n",
        "    layers.Dense(10,  activation='softmax'),\n",
        "])\n",
        "\n",
        "# Loading the saved weights\n",
        "dense_NN_adam_reload.load_weights('mnist_nn.weights.h5')\n",
        "\n",
        "# compile and evaluate\n",
        "dense_NN_adam_reload.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "loss_adam, acc_adam = dense_NN_adam_reload.evaluate(x_test_flat, y_test, verbose=0)\n",
        "print(f\"Dense‑NN (Adam, reloaded)  test accuracy: {acc_adam:.4f} — loss: {loss_adam:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6bJTGx-1wCg",
        "outputId": "660f9a0c-6de9-4a99-c08d-e09ae9f3ad43"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dense‑NN (Adam, reloaded)  test accuracy: 0.9814 — loss: 0.1031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dense NN — SGD\n",
        "dense_NN_sgd_reload = keras.Sequential([\n",
        "    keras.Input(shape=(28 * 28,)),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64,  activation='relu'),\n",
        "    layers.Dense(10,  activation='softmax'),\n",
        "])\n",
        "\n",
        "# Loading the saved weights\n",
        "dense_NN_sgd_reload.load_weights('mnist_nn_sgd.weights.h5')\n",
        "\n",
        "# compile and evaluate\n",
        "dense_NN_sgd_reload.compile(\n",
        "    optimizer='sgd',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "loss_sgd, acc_sgd = dense_NN_sgd_reload.evaluate(x_test_flat, y_test, verbose=0)\n",
        "print(f\"Dense‑NN (SGD, reloaded)  test accuracy: {acc_sgd:.4f} — loss: {loss_sgd:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KENum-zm3IF9",
        "outputId": "16b60db9-3f26-4bea-89b1-66ce851cf939"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dense‑NN (SGD, reloaded)  test accuracy: 0.9724 — loss: 0.0922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model — Adam\n",
        "cnn_reload = keras.Sequential([\n",
        "    layers.Input(shape=(28, 28, 1)),\n",
        "    layers.Conv2D(32, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(2),\n",
        "    layers.Conv2D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(2),\n",
        "    layers.Flatten(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# Loading the saved weights\n",
        "cnn_reload.load_weights('mnist_cnn.weights.h5')\n",
        "\n",
        "# compile and evaluate\n",
        "cnn_reload.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "loss_cnn, acc_cnn = cnn_reload.evaluate(x_test_cnn, y_test, verbose=0)\n",
        "print(f\"CNN (reloaded)            test accuracy: {acc_cnn:.4f} — loss: {loss_cnn:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQXFovQv3zHn",
        "outputId": "fad16793-d27d-424c-85cf-7cd726369559"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN (reloaded)            test accuracy: 0.9907 — loss: 0.0287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data handling\n",
        "*   Dense networks (Adam & SGD) flatten every 28 x 28 image to a 784-element vector, so spatial relationships are lost before the first weight is applied.\n",
        "*   CNN keeps the 28 x 28 grid (with a single-channel depth of 1).  Convolution layers therefore operate on small local windows and retain neighbourhood information.\n",
        "\n",
        "## Parameter sharing and parameter count\n",
        "*   Dense (Adam) - no sharing; every connection has its own weight  \n",
        "Total trainable parameters: ≈ 242k\n",
        "*   Dense (SGD) - identical architecture, therefore identical parameter behaviour  \n",
        "Total trainable parameters: ≈ 242 k\n",
        "*   CNN - each 3 x 3 filter is reused across all spatial positions, so a single set of nine weights serves the entire image  \n",
        "Total trainable parameters: 34,826\n",
        "\n",
        "*(The dense count is the sum of 784 x 256 + 256, 256 x 128 + 128, 128 x 64 + 64, and 64 x 10 + 10 = 242,762.)*\n",
        "\n",
        "## Training time (Colab GPU, 10 epochs)\n",
        "*   Dense nets: ~12 - 22s/epoch.\n",
        "*   CNN: ~60 - 85s/epoch.\n",
        "\n",
        "The longer CNN epochs reflect the heavier convolution operations even though the parameter set is much smaller. Additionally, the difference in time added up a lot, resulting in me having to wait a lot more for the CNN - 15 minutes as opposed to 1 minute and a half for the Dense nets. This extra time could add up if you are using a larger dataset or running a larger model making it a downside that should be heavily considered depending on the use case and the magnitude of the improvement (cost vs improvement). If the improvement isn't enough to warrant the extra time spent it may not be suitable for your implementation. It wasn't too bad for this implementation but regardless it was a very noticeable time difference as compared with the other networks.\n",
        "\n",
        "## Accuracy and loss (reloaded weights)\n",
        "\n",
        "Table of results:\n",
        "\n",
        "| Model        | **Validation accuracy** | **Validation loss** | **Test accuracy**  | **Test loss** |\n",
        "| ------------ | ----------------------- | ------------------- | ------------------ | ------------- |\n",
        "| Dense - Adam | **0.980 ≈ 98.0%**      | 0.105               | **0.981 ≈ 98.1%** | 0.103         |\n",
        "| Dense - SGD  | 0.970 ≈ 97.0%          | 0.095               | 0.972 ≈ 97.2%     | 0.092         |\n",
        "| CNN          | **0.991 ≈ 99.1%**      | 0.031               | **0.991 ≈ 99.1%** | 0.029         |\n",
        "\n",
        "I took the validation figures from the final epoch of each training run. The dense network trained with Adam reaches just under 98% validation accuracy (loss a little above 0.10) and 98.1% on the test set. When the same architecture uses plain SGD, validation accuracy is about 97% and test accuracy about 97.2%, with losses in the low-0.09 range (roughly a 1% dip because SGD's fixed step size learns more slowly in the ten-epoch window). The CNN keeps the 28 x 28 grid intact and hits about 99% on both validation and test, with loss around 0.03. The tiny gap between its validation and test scores shows it is generalising rather than memorising. Optimiser choice (Adam vs SGD) makes a noticeable difference inside the dense setup, but neither dense variant approaches the CNN's 99% accuracy or its much lower loss, even though the CNN has far fewer parameters.\n",
        "\n",
        "## Take-away\n",
        "Keeping the image structure intact and sharing kernel weights allows the CNN to generalise better with far fewer parameters, at the cost of higher per-epoch computation. Optimiser choice (Adam vs SGD) matters inside a given architecture, but it does not close the performance gap between a fully-connected network and a convolutional one on this task.\n"
      ],
      "metadata": {
        "id": "BtDyYqe86llv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KKxRRIy44myo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
